{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRO-AAbfvaK6"
      },
      "source": [
        "Read in dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_3MfHM2Ff5X",
        "outputId": "c5f99a14-8a18-42fa-e2e0-376ff62b1df7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/MyDrive/ML/Project/Asteroid_Updated.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,10,15,16,23,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "H8Qn9hy4FzpK",
        "outputId": "e18c7bca-aa3c-48c1-e76b-99cfa59bc9b5"
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>a</th>\n",
              "      <th>e</th>\n",
              "      <th>i</th>\n",
              "      <th>om</th>\n",
              "      <th>w</th>\n",
              "      <th>q</th>\n",
              "      <th>ad</th>\n",
              "      <th>per_y</th>\n",
              "      <th>data_arc</th>\n",
              "      <th>condition_code</th>\n",
              "      <th>n_obs_used</th>\n",
              "      <th>H</th>\n",
              "      <th>neo</th>\n",
              "      <th>pha</th>\n",
              "      <th>diameter</th>\n",
              "      <th>extent</th>\n",
              "      <th>albedo</th>\n",
              "      <th>rot_per</th>\n",
              "      <th>GM</th>\n",
              "      <th>BV</th>\n",
              "      <th>UB</th>\n",
              "      <th>IR</th>\n",
              "      <th>spec_B</th>\n",
              "      <th>spec_T</th>\n",
              "      <th>G</th>\n",
              "      <th>moid</th>\n",
              "      <th>class</th>\n",
              "      <th>n</th>\n",
              "      <th>per</th>\n",
              "      <th>ma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ceres</td>\n",
              "      <td>2.769165</td>\n",
              "      <td>0.076009</td>\n",
              "      <td>10.594067</td>\n",
              "      <td>80.305532</td>\n",
              "      <td>73.597694</td>\n",
              "      <td>2.558684</td>\n",
              "      <td>2.979647</td>\n",
              "      <td>4.608202</td>\n",
              "      <td>8822.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1002</td>\n",
              "      <td>3.340</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>939.4</td>\n",
              "      <td>964.4 x 964.2 x 891.8</td>\n",
              "      <td>0.0900</td>\n",
              "      <td>9.074170</td>\n",
              "      <td>62.6284</td>\n",
              "      <td>0.713</td>\n",
              "      <td>0.426</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>G</td>\n",
              "      <td>0.12</td>\n",
              "      <td>1.594780</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.213885</td>\n",
              "      <td>1683.145708</td>\n",
              "      <td>77.372096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pallas</td>\n",
              "      <td>2.772466</td>\n",
              "      <td>0.230337</td>\n",
              "      <td>34.836234</td>\n",
              "      <td>173.080063</td>\n",
              "      <td>310.048857</td>\n",
              "      <td>2.133865</td>\n",
              "      <td>3.411067</td>\n",
              "      <td>4.616444</td>\n",
              "      <td>72318.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8490</td>\n",
              "      <td>4.130</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>545</td>\n",
              "      <td>582x556x500</td>\n",
              "      <td>0.1010</td>\n",
              "      <td>7.813200</td>\n",
              "      <td>14.3000</td>\n",
              "      <td>0.635</td>\n",
              "      <td>0.284</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>0.11</td>\n",
              "      <td>1.233240</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.213503</td>\n",
              "      <td>1686.155999</td>\n",
              "      <td>59.699133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Juno</td>\n",
              "      <td>2.669150</td>\n",
              "      <td>0.256942</td>\n",
              "      <td>12.988919</td>\n",
              "      <td>169.852760</td>\n",
              "      <td>248.138626</td>\n",
              "      <td>1.983332</td>\n",
              "      <td>3.354967</td>\n",
              "      <td>4.360814</td>\n",
              "      <td>72684.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7104</td>\n",
              "      <td>5.330</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>246.596</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2140</td>\n",
              "      <td>7.210000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.824</td>\n",
              "      <td>0.433</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sk</td>\n",
              "      <td>S</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.034540</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.226019</td>\n",
              "      <td>1592.787285</td>\n",
              "      <td>34.925016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Vesta</td>\n",
              "      <td>2.361418</td>\n",
              "      <td>0.088721</td>\n",
              "      <td>7.141771</td>\n",
              "      <td>103.810804</td>\n",
              "      <td>150.728541</td>\n",
              "      <td>2.151909</td>\n",
              "      <td>2.570926</td>\n",
              "      <td>3.628837</td>\n",
              "      <td>24288.0</td>\n",
              "      <td>0</td>\n",
              "      <td>9325</td>\n",
              "      <td>3.200</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>525.4</td>\n",
              "      <td>572.6 x 557.2 x 446.4</td>\n",
              "      <td>0.4228</td>\n",
              "      <td>5.342128</td>\n",
              "      <td>17.8000</td>\n",
              "      <td>0.782</td>\n",
              "      <td>0.492</td>\n",
              "      <td>NaN</td>\n",
              "      <td>V</td>\n",
              "      <td>V</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.139480</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.271609</td>\n",
              "      <td>1325.432765</td>\n",
              "      <td>95.861936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Astraea</td>\n",
              "      <td>2.574249</td>\n",
              "      <td>0.191095</td>\n",
              "      <td>5.366988</td>\n",
              "      <td>141.576605</td>\n",
              "      <td>358.687607</td>\n",
              "      <td>2.082324</td>\n",
              "      <td>3.066174</td>\n",
              "      <td>4.130323</td>\n",
              "      <td>63507.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2916</td>\n",
              "      <td>6.850</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>106.699</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2740</td>\n",
              "      <td>16.806000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.826</td>\n",
              "      <td>0.411</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.095890</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.238632</td>\n",
              "      <td>1508.600458</td>\n",
              "      <td>282.366289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839709</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.812945</td>\n",
              "      <td>0.664688</td>\n",
              "      <td>4.695700</td>\n",
              "      <td>183.310012</td>\n",
              "      <td>234.618352</td>\n",
              "      <td>0.943214</td>\n",
              "      <td>4.682676</td>\n",
              "      <td>4.717914</td>\n",
              "      <td>17298.0</td>\n",
              "      <td>0</td>\n",
              "      <td>118</td>\n",
              "      <td>20.400</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.032397</td>\n",
              "      <td>APO</td>\n",
              "      <td>0.208911</td>\n",
              "      <td>1723.217927</td>\n",
              "      <td>156.905910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839710</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.645238</td>\n",
              "      <td>0.259376</td>\n",
              "      <td>12.574937</td>\n",
              "      <td>1.620020</td>\n",
              "      <td>339.568072</td>\n",
              "      <td>1.959126</td>\n",
              "      <td>3.331350</td>\n",
              "      <td>4.302346</td>\n",
              "      <td>16.0</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>17.507</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.956145</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.229090</td>\n",
              "      <td>1571.431965</td>\n",
              "      <td>13.366251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839711</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.373137</td>\n",
              "      <td>0.202053</td>\n",
              "      <td>0.732484</td>\n",
              "      <td>176.499082</td>\n",
              "      <td>198.026527</td>\n",
              "      <td>1.893638</td>\n",
              "      <td>2.852636</td>\n",
              "      <td>3.655884</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>18.071</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.893896</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.269600</td>\n",
              "      <td>1335.311579</td>\n",
              "      <td>355.351127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839712</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.260404</td>\n",
              "      <td>0.258348</td>\n",
              "      <td>9.661947</td>\n",
              "      <td>204.512448</td>\n",
              "      <td>148.496988</td>\n",
              "      <td>1.676433</td>\n",
              "      <td>2.844376</td>\n",
              "      <td>3.398501</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>18.060</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.680220</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.290018</td>\n",
              "      <td>1241.302609</td>\n",
              "      <td>15.320134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839713</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.546442</td>\n",
              "      <td>0.287672</td>\n",
              "      <td>5.356238</td>\n",
              "      <td>70.709555</td>\n",
              "      <td>273.483265</td>\n",
              "      <td>1.813901</td>\n",
              "      <td>3.278983</td>\n",
              "      <td>4.063580</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>17.406</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.815280</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.242551</td>\n",
              "      <td>1484.222588</td>\n",
              "      <td>20.432959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>839714 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           name         a         e  ...         n          per          ma\n",
              "0         Ceres  2.769165  0.076009  ...  0.213885  1683.145708   77.372096\n",
              "1        Pallas  2.772466  0.230337  ...  0.213503  1686.155999   59.699133\n",
              "2          Juno  2.669150  0.256942  ...  0.226019  1592.787285   34.925016\n",
              "3         Vesta  2.361418  0.088721  ...  0.271609  1325.432765   95.861936\n",
              "4       Astraea  2.574249  0.191095  ...  0.238632  1508.600458  282.366289\n",
              "...         ...       ...       ...  ...       ...          ...         ...\n",
              "839709      NaN  2.812945  0.664688  ...  0.208911  1723.217927  156.905910\n",
              "839710      NaN  2.645238  0.259376  ...  0.229090  1571.431965   13.366251\n",
              "839711      NaN  2.373137  0.202053  ...  0.269600  1335.311579  355.351127\n",
              "839712      NaN  2.260404  0.258348  ...  0.290018  1241.302609   15.320134\n",
              "839713      NaN  2.546442  0.287672  ...  0.242551  1484.222588   20.432959\n",
              "\n",
              "[839714 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPscpuZEvdW5"
      },
      "source": [
        "Drop all samples that are not considered physically hazardous from the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "JtSJzodFF_qd",
        "outputId": "7c6952c6-4dec-4e93-d945-a4fea1ff578f"
      },
      "source": [
        "data = dataset[(dataset['pha'] == \"Y\")]\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>a</th>\n",
              "      <th>e</th>\n",
              "      <th>i</th>\n",
              "      <th>om</th>\n",
              "      <th>w</th>\n",
              "      <th>q</th>\n",
              "      <th>ad</th>\n",
              "      <th>per_y</th>\n",
              "      <th>data_arc</th>\n",
              "      <th>condition_code</th>\n",
              "      <th>n_obs_used</th>\n",
              "      <th>H</th>\n",
              "      <th>neo</th>\n",
              "      <th>pha</th>\n",
              "      <th>diameter</th>\n",
              "      <th>extent</th>\n",
              "      <th>albedo</th>\n",
              "      <th>rot_per</th>\n",
              "      <th>GM</th>\n",
              "      <th>BV</th>\n",
              "      <th>UB</th>\n",
              "      <th>IR</th>\n",
              "      <th>spec_B</th>\n",
              "      <th>spec_T</th>\n",
              "      <th>G</th>\n",
              "      <th>moid</th>\n",
              "      <th>class</th>\n",
              "      <th>n</th>\n",
              "      <th>per</th>\n",
              "      <th>ma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1565</th>\n",
              "      <td>Icarus</td>\n",
              "      <td>1.078095</td>\n",
              "      <td>0.826928</td>\n",
              "      <td>22.826494</td>\n",
              "      <td>88.004724</td>\n",
              "      <td>31.380821</td>\n",
              "      <td>0.186588</td>\n",
              "      <td>1.969601</td>\n",
              "      <td>1.119421</td>\n",
              "      <td>25593.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1008</td>\n",
              "      <td>16.900</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.51</td>\n",
              "      <td>2.27260</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.774</td>\n",
              "      <td>0.520</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.034275</td>\n",
              "      <td>APO</td>\n",
              "      <td>0.880479</td>\n",
              "      <td>408.868580</td>\n",
              "      <td>199.925955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>Geographos</td>\n",
              "      <td>1.245302</td>\n",
              "      <td>0.335441</td>\n",
              "      <td>13.337348</td>\n",
              "      <td>337.195400</td>\n",
              "      <td>276.915035</td>\n",
              "      <td>0.827577</td>\n",
              "      <td>1.663027</td>\n",
              "      <td>1.389698</td>\n",
              "      <td>24903.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4449</td>\n",
              "      <td>15.600</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>2.56</td>\n",
              "      <td>5.0x2.0x2.1</td>\n",
              "      <td>0.29</td>\n",
              "      <td>5.22204</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.862</td>\n",
              "      <td>0.471</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.029829</td>\n",
              "      <td>APO</td>\n",
              "      <td>0.709238</td>\n",
              "      <td>507.587166</td>\n",
              "      <td>311.532967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1861</th>\n",
              "      <td>Apollo</td>\n",
              "      <td>1.470045</td>\n",
              "      <td>0.559823</td>\n",
              "      <td>6.355123</td>\n",
              "      <td>35.630545</td>\n",
              "      <td>285.970752</td>\n",
              "      <td>0.647079</td>\n",
              "      <td>2.293011</td>\n",
              "      <td>1.782396</td>\n",
              "      <td>32277.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1681</td>\n",
              "      <td>16.250</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.25</td>\n",
              "      <td>3.06500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.819</td>\n",
              "      <td>0.481</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "      <td>Q</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.025921</td>\n",
              "      <td>APO</td>\n",
              "      <td>0.552978</td>\n",
              "      <td>651.020130</td>\n",
              "      <td>227.379826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>Midas</td>\n",
              "      <td>1.776600</td>\n",
              "      <td>0.650353</td>\n",
              "      <td>39.826896</td>\n",
              "      <td>356.886302</td>\n",
              "      <td>267.797740</td>\n",
              "      <td>0.621182</td>\n",
              "      <td>2.932017</td>\n",
              "      <td>2.368059</td>\n",
              "      <td>16761.0</td>\n",
              "      <td>0</td>\n",
              "      <td>910</td>\n",
              "      <td>15.200</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>3.4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.22000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>V</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.003711</td>\n",
              "      <td>APO</td>\n",
              "      <td>0.416217</td>\n",
              "      <td>864.933552</td>\n",
              "      <td>146.268712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2100</th>\n",
              "      <td>Adonis</td>\n",
              "      <td>1.874230</td>\n",
              "      <td>0.764422</td>\n",
              "      <td>1.323673</td>\n",
              "      <td>349.570099</td>\n",
              "      <td>43.550566</td>\n",
              "      <td>0.441527</td>\n",
              "      <td>3.306933</td>\n",
              "      <td>2.565917</td>\n",
              "      <td>30009.0</td>\n",
              "      <td>0</td>\n",
              "      <td>126</td>\n",
              "      <td>18.800</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.011622</td>\n",
              "      <td>APO</td>\n",
              "      <td>0.384122</td>\n",
              "      <td>937.201107</td>\n",
              "      <td>182.529745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839539</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.275157</td>\n",
              "      <td>0.842180</td>\n",
              "      <td>4.993691</td>\n",
              "      <td>226.421186</td>\n",
              "      <td>297.729427</td>\n",
              "      <td>0.359065</td>\n",
              "      <td>4.191250</td>\n",
              "      <td>3.431827</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8</td>\n",
              "      <td>46</td>\n",
              "      <td>21.937</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.006780</td>\n",
              "      <td>APO</td>\n",
              "      <td>0.287202</td>\n",
              "      <td>1253.474652</td>\n",
              "      <td>344.037968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839574</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.519163</td>\n",
              "      <td>0.327111</td>\n",
              "      <td>12.483794</td>\n",
              "      <td>188.591468</td>\n",
              "      <td>155.155912</td>\n",
              "      <td>1.022229</td>\n",
              "      <td>2.016098</td>\n",
              "      <td>1.872470</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8</td>\n",
              "      <td>23</td>\n",
              "      <td>21.558</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.039600</td>\n",
              "      <td>AMO</td>\n",
              "      <td>0.526377</td>\n",
              "      <td>683.919833</td>\n",
              "      <td>35.564429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839645</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.984984</td>\n",
              "      <td>0.737657</td>\n",
              "      <td>33.581588</td>\n",
              "      <td>38.820814</td>\n",
              "      <td>257.133890</td>\n",
              "      <td>0.520747</td>\n",
              "      <td>3.449220</td>\n",
              "      <td>2.796686</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9</td>\n",
              "      <td>28</td>\n",
              "      <td>21.395</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.047545</td>\n",
              "      <td>APO</td>\n",
              "      <td>0.352427</td>\n",
              "      <td>1021.489395</td>\n",
              "      <td>17.388067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839697</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.098598</td>\n",
              "      <td>0.846732</td>\n",
              "      <td>10.421247</td>\n",
              "      <td>260.210604</td>\n",
              "      <td>288.045149</td>\n",
              "      <td>0.321647</td>\n",
              "      <td>3.875549</td>\n",
              "      <td>3.040200</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9</td>\n",
              "      <td>22</td>\n",
              "      <td>19.566</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.030428</td>\n",
              "      <td>APO</td>\n",
              "      <td>0.324198</td>\n",
              "      <td>1110.433114</td>\n",
              "      <td>331.708570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839709</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.812945</td>\n",
              "      <td>0.664688</td>\n",
              "      <td>4.695700</td>\n",
              "      <td>183.310012</td>\n",
              "      <td>234.618352</td>\n",
              "      <td>0.943214</td>\n",
              "      <td>4.682676</td>\n",
              "      <td>4.717914</td>\n",
              "      <td>17298.0</td>\n",
              "      <td>0</td>\n",
              "      <td>118</td>\n",
              "      <td>20.400</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.032397</td>\n",
              "      <td>APO</td>\n",
              "      <td>0.208911</td>\n",
              "      <td>1723.217927</td>\n",
              "      <td>156.905910</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2015 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              name         a         e  ...         n          per          ma\n",
              "1565        Icarus  1.078095  0.826928  ...  0.880479   408.868580  199.925955\n",
              "1619    Geographos  1.245302  0.335441  ...  0.709238   507.587166  311.532967\n",
              "1861        Apollo  1.470045  0.559823  ...  0.552978   651.020130  227.379826\n",
              "1980         Midas  1.776600  0.650353  ...  0.416217   864.933552  146.268712\n",
              "2100        Adonis  1.874230  0.764422  ...  0.384122   937.201107  182.529745\n",
              "...            ...       ...       ...  ...       ...          ...         ...\n",
              "839539         NaN  2.275157  0.842180  ...  0.287202  1253.474652  344.037968\n",
              "839574         NaN  1.519163  0.327111  ...  0.526377   683.919833   35.564429\n",
              "839645         NaN  1.984984  0.737657  ...  0.352427  1021.489395   17.388067\n",
              "839697         NaN  2.098598  0.846732  ...  0.324198  1110.433114  331.708570\n",
              "839709         NaN  2.812945  0.664688  ...  0.208911  1723.217927  156.905910\n",
              "\n",
              "[2015 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvbx9kbhvmMB"
      },
      "source": [
        "Simple data management and preprocessing.\n",
        "\n",
        "Encode categorical columns using dictionaries and label encoder.\n",
        "Drop unecessary columns from dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAAzMVo1J8TB",
        "outputId": "2440e82c-23fd-4540-c7f9-f3702f7d5018"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder as le\n",
        "\n",
        "data['pha'] = data['pha'].map({'Y': 1, 'N': 0})\n",
        "data['neo'] = data['neo'].map({'Y': 1, 'N': 0})\n",
        "data['condition_code'] = data['condition_code'].map({0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 'D': 11, 'E': 12})\n",
        "data['class'] = le().fit_transform(data['class'])\n",
        "\n",
        "columns_c = ['name', 'extent', 'albedo', 'rot_per', 'GM', 'BV', 'G', 'UB', 'IR', 'spec_B', 'spec_T', 'diameter', 'w', 'per', 'ma']\n",
        "data = data.drop(columns=columns_c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh_i8o_YJ_Xa"
      },
      "source": [
        "data.dropna(how='all', axis=1, inplace=True)\n",
        "data.dropna(how='any', axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5BA9PdMKoNd"
      },
      "source": [
        "x = data.values\n",
        "y = data['pha'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyOPjkyev55I"
      },
      "source": [
        "Set up for the VAE:\n",
        "\n",
        "  sampling function\n",
        "  \n",
        "  scaling of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_csq7ezrLgb1"
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def sampling(z_params):\n",
        "        z_mean, z_log_var = z_params\n",
        "        batch = K.shape(z_mean)[0]\n",
        "        dims = K.int_shape(z_mean)[1]\n",
        "        epsilon = K.random_normal(shape=(batch, dims))\n",
        "        return z_mean + K.exp(0.5 * z_log_var) * epsilon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q3BrbghLrj_",
        "outputId": "0d7739c4-99d9-40ab-cfed-b60a993dd329"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import make_column_transformer\n",
        "import numpy as np\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit(x)\n",
        "x_train = sc.transform(x)\n",
        "og_dim = x_train.shape[1]\n",
        "og_dim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEgKu9K3gEil",
        "outputId": "bc8b4631-f6aa-4b69-ed8e-3a6d66d63098"
      },
      "source": [
        "x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.01467967,  1.85854102,  0.6996742 , ...,  0.79129946,\n",
              "        -0.16201048,  0.90361791],\n",
              "       [-0.70698682, -0.95722136, -0.05168687, ...,  0.48230497,\n",
              "        -0.16201048,  0.37129872],\n",
              "       [-0.29341895,  0.32828274, -0.60454714, ...,  0.21076204,\n",
              "        -0.16201048, -0.11444981],\n",
              "       ...,\n",
              "       [ 0.77096247,  1.37497473, -0.81979394, ..., -1.56172388,\n",
              "        -0.16201048, -0.78840775],\n",
              "       [ 0.46967448,  1.57332602, -0.14203208, ...,  0.79837418,\n",
              "        -0.16201048, -0.6493184 ],\n",
              "       [ 2.05990634,  0.81241257, -0.16683184, ...,  1.62832691,\n",
              "        -0.16201048, -1.16118874]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D2lS9U8MJ95"
      },
      "source": [
        "import math\n",
        "input_shape = (og_dim, )\n",
        "inter_dim = 15\n",
        "batch_size = math.ceil(math.sqrt(x_train.shape[0]))\n",
        "latent_dim = 2\n",
        "epochs = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouRPoZxqwIeE"
      },
      "source": [
        "Setup for the VAE: \n",
        "\n",
        "  encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_vMo1SeM1S7"
      },
      "source": [
        "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "inputs = Input(shape=input_shape)\n",
        "bn = BatchNormalization()(inputs)\n",
        "dp = Dropout(0.2)(bn)\n",
        "q = Dense(inter_dim, activation='sigmoid')(dp)\n",
        "q = Dropout(0.2)(q)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4LgAUwRNaJE"
      },
      "source": [
        "z_mean = Dense(latent_dim)(q)\n",
        "z_log_var = Dense(latent_dim)(q)\n",
        "z_params = [z_mean, z_log_var]\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))(z_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCFrA0zqNwyu"
      },
      "source": [
        "encoder = Model(inputs, [z_mean, z_log_var, z])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUadqp7HN5Vg"
      },
      "source": [
        "decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHX1cKrKN4E3"
      },
      "source": [
        "latent_inputs = Input(shape=(latent_dim,))\n",
        "q = Dense(inter_dim, activation='relu')(latent_inputs)\n",
        "r_outputs = Dense(og_dim)(q)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4ksnzzeONwP"
      },
      "source": [
        "decoder = Model(latent_inputs, r_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqE0a2IYORjO"
      },
      "source": [
        "Variational Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuEPGXO-OT_0"
      },
      "source": [
        "outputs = decoder(encoder(inputs)[2])\n",
        "\n",
        "vae = Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3qslS88Oexn"
      },
      "source": [
        "from tensorflow.keras.losses import mse\n",
        "r_loss = mse(inputs,outputs)\n",
        "r_loss = og_dim * r_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPuWIBd6wRiZ"
      },
      "source": [
        "Compile VAE and fit to data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zwdqdl4OO8Hs",
        "outputId": "3e89decf-80c0-4499-e51e-2980d03c69ef"
      },
      "source": [
        "vae.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "history = vae.fit(x_train, x_train, epochs=epochs,batch_size=batch_size, validation_data=(x_train,x_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "31/31 [==============================] - 1s 11ms/step - loss: 0.1118 - val_loss: -0.0400\n",
            "Epoch 2/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.0262 - val_loss: -0.0906\n",
            "Epoch 3/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.0849 - val_loss: -0.1695\n",
            "Epoch 4/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.1781 - val_loss: -0.2062\n",
            "Epoch 5/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.0959 - val_loss: -0.2185\n",
            "Epoch 6/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.1024 - val_loss: -0.2519\n",
            "Epoch 7/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: -0.2293 - val_loss: -0.2651\n",
            "Epoch 8/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.2749 - val_loss: -0.3150\n",
            "Epoch 9/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.2415 - val_loss: -0.3765\n",
            "Epoch 10/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.2620 - val_loss: -0.3471\n",
            "Epoch 11/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.1795 - val_loss: -0.3452\n",
            "Epoch 12/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.3317 - val_loss: -0.3452\n",
            "Epoch 13/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.3215 - val_loss: -0.4350\n",
            "Epoch 14/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.2961 - val_loss: -0.3663\n",
            "Epoch 15/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.2931 - val_loss: -0.4028\n",
            "Epoch 16/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.2834 - val_loss: -0.4159\n",
            "Epoch 17/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.2915 - val_loss: -0.4247\n",
            "Epoch 18/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.2840 - val_loss: -0.4219\n",
            "Epoch 19/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.3251 - val_loss: -0.4300\n",
            "Epoch 20/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.3860 - val_loss: -0.3852\n",
            "Epoch 21/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.2994 - val_loss: -0.4277\n",
            "Epoch 22/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.3153 - val_loss: -0.3580\n",
            "Epoch 23/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.3408 - val_loss: -0.3895\n",
            "Epoch 24/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.3956 - val_loss: -0.4808\n",
            "Epoch 25/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.3485 - val_loss: -0.4278\n",
            "Epoch 26/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.3817 - val_loss: -0.5061\n",
            "Epoch 27/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.2596 - val_loss: -0.3715\n",
            "Epoch 28/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.2360 - val_loss: -0.4212\n",
            "Epoch 29/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.3472 - val_loss: -0.4877\n",
            "Epoch 30/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.4258 - val_loss: -0.4340\n",
            "Epoch 31/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.3536 - val_loss: -0.4807\n",
            "Epoch 32/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.3775 - val_loss: -0.5033\n",
            "Epoch 33/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.3900 - val_loss: -0.5253\n",
            "Epoch 34/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.3869 - val_loss: -0.5312\n",
            "Epoch 35/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.4504 - val_loss: -0.5111\n",
            "Epoch 36/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.4381 - val_loss: -0.5108\n",
            "Epoch 37/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.4508 - val_loss: -0.5965\n",
            "Epoch 38/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.5107 - val_loss: -0.6292\n",
            "Epoch 39/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.5828 - val_loss: -0.6562\n",
            "Epoch 40/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.6039 - val_loss: -0.6828\n",
            "Epoch 41/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.5434 - val_loss: -0.7201\n",
            "Epoch 42/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.4785 - val_loss: -0.6993\n",
            "Epoch 43/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.6088 - val_loss: -0.7229\n",
            "Epoch 44/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.6348 - val_loss: -0.7649\n",
            "Epoch 45/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.6068 - val_loss: -0.6965\n",
            "Epoch 46/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.6513 - val_loss: -0.7874\n",
            "Epoch 47/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.6416 - val_loss: -0.7672\n",
            "Epoch 48/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.6413 - val_loss: -0.7469\n",
            "Epoch 49/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.6146 - val_loss: -0.6947\n",
            "Epoch 50/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.6063 - val_loss: -0.7934\n",
            "Epoch 51/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.6769 - val_loss: -0.8203\n",
            "Epoch 52/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.7263 - val_loss: -0.8785\n",
            "Epoch 53/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.6952 - val_loss: -0.9992\n",
            "Epoch 54/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.7935 - val_loss: -0.9282\n",
            "Epoch 55/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.8381 - val_loss: -1.0255\n",
            "Epoch 56/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.8667 - val_loss: -0.9663\n",
            "Epoch 57/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.8826 - val_loss: -1.0285\n",
            "Epoch 58/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.8380 - val_loss: -1.0071\n",
            "Epoch 59/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.8290 - val_loss: -1.0494\n",
            "Epoch 60/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.7815 - val_loss: -1.0743\n",
            "Epoch 61/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.8438 - val_loss: -1.0725\n",
            "Epoch 62/300\n",
            "31/31 [==============================] - 0s 6ms/step - loss: -0.9012 - val_loss: -1.0670\n",
            "Epoch 63/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.9296 - val_loss: -1.0953\n",
            "Epoch 64/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.8541 - val_loss: -1.0715\n",
            "Epoch 65/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.8992 - val_loss: -1.1165\n",
            "Epoch 66/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.9668 - val_loss: -1.1147\n",
            "Epoch 67/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.9752 - val_loss: -1.2057\n",
            "Epoch 68/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.9319 - val_loss: -1.1979\n",
            "Epoch 69/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.0612 - val_loss: -1.1547\n",
            "Epoch 70/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.9221 - val_loss: -1.1413\n",
            "Epoch 71/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.9462 - val_loss: -1.0939\n",
            "Epoch 72/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.9977 - val_loss: -1.1370\n",
            "Epoch 73/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.9605 - val_loss: -1.1616\n",
            "Epoch 74/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -0.9987 - val_loss: -1.1551\n",
            "Epoch 75/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.0311 - val_loss: -1.2480\n",
            "Epoch 76/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.0480 - val_loss: -1.1664\n",
            "Epoch 77/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -0.9871 - val_loss: -1.2274\n",
            "Epoch 78/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.0035 - val_loss: -1.2568\n",
            "Epoch 79/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.0641 - val_loss: -1.2692\n",
            "Epoch 80/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.1174 - val_loss: -1.2403\n",
            "Epoch 81/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.0472 - val_loss: -1.3150\n",
            "Epoch 82/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.1262 - val_loss: -1.3083\n",
            "Epoch 83/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.1639 - val_loss: -1.3083\n",
            "Epoch 84/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.0879 - val_loss: -1.3217\n",
            "Epoch 85/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.0440 - val_loss: -1.2482\n",
            "Epoch 86/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.0678 - val_loss: -1.2481\n",
            "Epoch 87/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.0667 - val_loss: -1.2992\n",
            "Epoch 88/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.0777 - val_loss: -1.3474\n",
            "Epoch 89/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.1550 - val_loss: -1.3505\n",
            "Epoch 90/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.0936 - val_loss: -1.2079\n",
            "Epoch 91/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.1033 - val_loss: -1.1903\n",
            "Epoch 92/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.0932 - val_loss: -1.2263\n",
            "Epoch 93/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.0396 - val_loss: -1.3033\n",
            "Epoch 94/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.1415 - val_loss: -1.3728\n",
            "Epoch 95/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.1421 - val_loss: -1.3439\n",
            "Epoch 96/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.1399 - val_loss: -1.3692\n",
            "Epoch 97/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.1711 - val_loss: -1.4118\n",
            "Epoch 98/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.1822 - val_loss: -1.3874\n",
            "Epoch 99/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.2388 - val_loss: -1.4403\n",
            "Epoch 100/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.2289 - val_loss: -1.4995\n",
            "Epoch 101/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.2356 - val_loss: -1.4263\n",
            "Epoch 102/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.2424 - val_loss: -1.5079\n",
            "Epoch 103/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.2161 - val_loss: -1.5212\n",
            "Epoch 104/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.2618 - val_loss: -1.4484\n",
            "Epoch 105/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.3063 - val_loss: -1.5195\n",
            "Epoch 106/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.2984 - val_loss: -1.4790\n",
            "Epoch 107/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.3399 - val_loss: -1.5190\n",
            "Epoch 108/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.3526 - val_loss: -1.5178\n",
            "Epoch 109/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.3097 - val_loss: -1.5723\n",
            "Epoch 110/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.3600 - val_loss: -1.5608\n",
            "Epoch 111/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.3448 - val_loss: -1.5782\n",
            "Epoch 112/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.3910 - val_loss: -1.5821\n",
            "Epoch 113/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.3980 - val_loss: -1.5850\n",
            "Epoch 114/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4062 - val_loss: -1.6696\n",
            "Epoch 115/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.3503 - val_loss: -1.5827\n",
            "Epoch 116/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4325 - val_loss: -1.6773\n",
            "Epoch 117/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4205 - val_loss: -1.6609\n",
            "Epoch 118/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.3890 - val_loss: -1.6800\n",
            "Epoch 119/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4626 - val_loss: -1.7015\n",
            "Epoch 120/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.4346 - val_loss: -1.6843\n",
            "Epoch 121/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4056 - val_loss: -1.6797\n",
            "Epoch 122/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.3926 - val_loss: -1.6800\n",
            "Epoch 123/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.3721 - val_loss: -1.6447\n",
            "Epoch 124/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.4696 - val_loss: -1.6640\n",
            "Epoch 125/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.3938 - val_loss: -1.6636\n",
            "Epoch 126/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4628 - val_loss: -1.6570\n",
            "Epoch 127/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: -1.4681 - val_loss: -1.6754\n",
            "Epoch 128/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4636 - val_loss: -1.6707\n",
            "Epoch 129/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4930 - val_loss: -1.6482\n",
            "Epoch 130/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.4076 - val_loss: -1.6405\n",
            "Epoch 131/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4409 - val_loss: -1.6433\n",
            "Epoch 132/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.4956 - val_loss: -1.6260\n",
            "Epoch 133/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.4899 - val_loss: -1.6794\n",
            "Epoch 134/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4830 - val_loss: -1.6689\n",
            "Epoch 135/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5190 - val_loss: -1.6798\n",
            "Epoch 136/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4405 - val_loss: -1.7372\n",
            "Epoch 137/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.4834 - val_loss: -1.7214\n",
            "Epoch 138/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.5246 - val_loss: -1.7359\n",
            "Epoch 139/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.4699 - val_loss: -1.7211\n",
            "Epoch 140/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5355 - val_loss: -1.7193\n",
            "Epoch 141/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.5122 - val_loss: -1.7647\n",
            "Epoch 142/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5021 - val_loss: -1.7206\n",
            "Epoch 143/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.5713 - val_loss: -1.7513\n",
            "Epoch 144/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5197 - val_loss: -1.7326\n",
            "Epoch 145/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5360 - val_loss: -1.7203\n",
            "Epoch 146/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5511 - val_loss: -1.7967\n",
            "Epoch 147/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5179 - val_loss: -1.7451\n",
            "Epoch 148/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.5087 - val_loss: -1.7850\n",
            "Epoch 149/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5521 - val_loss: -1.7552\n",
            "Epoch 150/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5154 - val_loss: -1.7551\n",
            "Epoch 151/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5229 - val_loss: -1.7268\n",
            "Epoch 152/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.5258 - val_loss: -1.6812\n",
            "Epoch 153/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4880 - val_loss: -1.7048\n",
            "Epoch 154/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4914 - val_loss: -1.7313\n",
            "Epoch 155/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4481 - val_loss: -1.6973\n",
            "Epoch 156/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5017 - val_loss: -1.7089\n",
            "Epoch 157/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.6017 - val_loss: -1.7069\n",
            "Epoch 158/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.4961 - val_loss: -1.7541\n",
            "Epoch 159/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.5521 - val_loss: -1.7443\n",
            "Epoch 160/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.5818 - val_loss: -1.7506\n",
            "Epoch 161/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.5526 - val_loss: -1.7871\n",
            "Epoch 162/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5783 - val_loss: -1.7671\n",
            "Epoch 163/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5809 - val_loss: -1.7927\n",
            "Epoch 164/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6050 - val_loss: -1.8443\n",
            "Epoch 165/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.6300 - val_loss: -1.7979\n",
            "Epoch 166/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5929 - val_loss: -1.7721\n",
            "Epoch 167/300\n",
            "31/31 [==============================] - 0s 6ms/step - loss: -1.5700 - val_loss: -1.8211\n",
            "Epoch 168/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5606 - val_loss: -1.7879\n",
            "Epoch 169/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6191 - val_loss: -1.8072\n",
            "Epoch 170/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.6226 - val_loss: -1.8183\n",
            "Epoch 171/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6185 - val_loss: -1.8265\n",
            "Epoch 172/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5844 - val_loss: -1.8162\n",
            "Epoch 173/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.6264 - val_loss: -1.7935\n",
            "Epoch 174/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6560 - val_loss: -1.7717\n",
            "Epoch 175/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5736 - val_loss: -1.8241\n",
            "Epoch 176/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6100 - val_loss: -1.8049\n",
            "Epoch 177/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6147 - val_loss: -1.8376\n",
            "Epoch 178/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5985 - val_loss: -1.7711\n",
            "Epoch 179/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.4914 - val_loss: -1.7146\n",
            "Epoch 180/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5440 - val_loss: -1.7040\n",
            "Epoch 181/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.5483 - val_loss: -1.8249\n",
            "Epoch 182/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6543 - val_loss: -1.8240\n",
            "Epoch 183/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.6052 - val_loss: -1.8805\n",
            "Epoch 184/300\n",
            "31/31 [==============================] - 0s 6ms/step - loss: -1.6565 - val_loss: -1.8536\n",
            "Epoch 185/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6329 - val_loss: -1.8845\n",
            "Epoch 186/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.6473 - val_loss: -1.8163\n",
            "Epoch 187/300\n",
            "31/31 [==============================] - 0s 6ms/step - loss: -1.6747 - val_loss: -1.8553\n",
            "Epoch 188/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6387 - val_loss: -1.9020\n",
            "Epoch 189/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6727 - val_loss: -1.8619\n",
            "Epoch 190/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.6915 - val_loss: -1.9120\n",
            "Epoch 191/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.7147 - val_loss: -1.9153\n",
            "Epoch 192/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.6855 - val_loss: -1.9132\n",
            "Epoch 193/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7188 - val_loss: -1.9100\n",
            "Epoch 194/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7056 - val_loss: -1.9534\n",
            "Epoch 195/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7486 - val_loss: -1.9937\n",
            "Epoch 196/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.7183 - val_loss: -1.9093\n",
            "Epoch 197/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.6880 - val_loss: -1.9299\n",
            "Epoch 198/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6726 - val_loss: -1.9820\n",
            "Epoch 199/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6797 - val_loss: -1.9481\n",
            "Epoch 200/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7458 - val_loss: -1.9149\n",
            "Epoch 201/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.6824 - val_loss: -1.9032\n",
            "Epoch 202/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.7196 - val_loss: -1.9730\n",
            "Epoch 203/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.7434 - val_loss: -1.9798\n",
            "Epoch 204/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.7557 - val_loss: -1.9879\n",
            "Epoch 205/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7154 - val_loss: -1.9830\n",
            "Epoch 206/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8088 - val_loss: -1.9831\n",
            "Epoch 207/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7776 - val_loss: -2.0345\n",
            "Epoch 208/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.6968 - val_loss: -1.8983\n",
            "Epoch 209/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6885 - val_loss: -1.8867\n",
            "Epoch 210/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7036 - val_loss: -1.9339\n",
            "Epoch 211/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6805 - val_loss: -1.9274\n",
            "Epoch 212/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7375 - val_loss: -1.9292\n",
            "Epoch 213/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7088 - val_loss: -1.9668\n",
            "Epoch 214/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.6727 - val_loss: -1.9246\n",
            "Epoch 215/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.7800 - val_loss: -1.9332\n",
            "Epoch 216/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7901 - val_loss: -2.0039\n",
            "Epoch 217/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.7507 - val_loss: -1.9776\n",
            "Epoch 218/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7427 - val_loss: -1.9607\n",
            "Epoch 219/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.6548 - val_loss: -1.9848\n",
            "Epoch 220/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.7506 - val_loss: -1.9663\n",
            "Epoch 221/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7533 - val_loss: -1.9969\n",
            "Epoch 222/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.7408 - val_loss: -2.0401\n",
            "Epoch 223/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7681 - val_loss: -2.0122\n",
            "Epoch 224/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7407 - val_loss: -2.0448\n",
            "Epoch 225/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7463 - val_loss: -2.0249\n",
            "Epoch 226/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7487 - val_loss: -2.0195\n",
            "Epoch 227/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8225 - val_loss: -2.0538\n",
            "Epoch 228/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7562 - val_loss: -2.0348\n",
            "Epoch 229/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8388 - val_loss: -2.0288\n",
            "Epoch 230/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7943 - val_loss: -2.0257\n",
            "Epoch 231/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.7353 - val_loss: -2.0218\n",
            "Epoch 232/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8121 - val_loss: -2.0706\n",
            "Epoch 233/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8238 - val_loss: -2.0472\n",
            "Epoch 234/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.7640 - val_loss: -2.0506\n",
            "Epoch 235/300\n",
            "31/31 [==============================] - 0s 6ms/step - loss: -1.8149 - val_loss: -2.0679\n",
            "Epoch 236/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8382 - val_loss: -2.0710\n",
            "Epoch 237/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8449 - val_loss: -2.0868\n",
            "Epoch 238/300\n",
            "31/31 [==============================] - 0s 6ms/step - loss: -1.7691 - val_loss: -2.0583\n",
            "Epoch 239/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8354 - val_loss: -2.0823\n",
            "Epoch 240/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8543 - val_loss: -2.1169\n",
            "Epoch 241/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.8501 - val_loss: -2.1361\n",
            "Epoch 242/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8613 - val_loss: -2.0903\n",
            "Epoch 243/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8442 - val_loss: -2.0813\n",
            "Epoch 244/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.8637 - val_loss: -2.1360\n",
            "Epoch 245/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8526 - val_loss: -2.1328\n",
            "Epoch 246/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.8735 - val_loss: -2.1154\n",
            "Epoch 247/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.8603 - val_loss: -2.0968\n",
            "Epoch 248/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8559 - val_loss: -2.1351\n",
            "Epoch 249/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9303 - val_loss: -2.1233\n",
            "Epoch 250/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.8448 - val_loss: -2.1546\n",
            "Epoch 251/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9072 - val_loss: -2.1603\n",
            "Epoch 252/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9275 - val_loss: -2.1842\n",
            "Epoch 253/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9299 - val_loss: -2.1648\n",
            "Epoch 254/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9382 - val_loss: -2.2029\n",
            "Epoch 255/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9370 - val_loss: -2.1899\n",
            "Epoch 256/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9108 - val_loss: -2.1923\n",
            "Epoch 257/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9489 - val_loss: -2.2054\n",
            "Epoch 258/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.8990 - val_loss: -2.1912\n",
            "Epoch 259/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9362 - val_loss: -2.2202\n",
            "Epoch 260/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9154 - val_loss: -2.2329\n",
            "Epoch 261/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9741 - val_loss: -2.1972\n",
            "Epoch 262/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -2.0013 - val_loss: -2.2171\n",
            "Epoch 263/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9571 - val_loss: -2.2494\n",
            "Epoch 264/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9525 - val_loss: -2.2349\n",
            "Epoch 265/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9942 - val_loss: -2.2295\n",
            "Epoch 266/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9730 - val_loss: -2.2249\n",
            "Epoch 267/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0054 - val_loss: -2.2326\n",
            "Epoch 268/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0112 - val_loss: -2.2482\n",
            "Epoch 269/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9773 - val_loss: -2.2776\n",
            "Epoch 270/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9656 - val_loss: -2.2602\n",
            "Epoch 271/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9334 - val_loss: -2.2530\n",
            "Epoch 272/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9659 - val_loss: -2.2561\n",
            "Epoch 273/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9698 - val_loss: -2.2670\n",
            "Epoch 274/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9422 - val_loss: -2.2599\n",
            "Epoch 275/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9539 - val_loss: -2.2833\n",
            "Epoch 276/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9718 - val_loss: -2.2961\n",
            "Epoch 277/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9434 - val_loss: -2.3104\n",
            "Epoch 278/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0101 - val_loss: -2.3018\n",
            "Epoch 279/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9999 - val_loss: -2.2838\n",
            "Epoch 280/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9909 - val_loss: -2.2904\n",
            "Epoch 281/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -2.0406 - val_loss: -2.3027\n",
            "Epoch 282/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0604 - val_loss: -2.2720\n",
            "Epoch 283/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9890 - val_loss: -2.3193\n",
            "Epoch 284/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0315 - val_loss: -2.3016\n",
            "Epoch 285/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0036 - val_loss: -2.3252\n",
            "Epoch 286/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0443 - val_loss: -2.3903\n",
            "Epoch 287/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0708 - val_loss: -2.3575\n",
            "Epoch 288/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -2.0640 - val_loss: -2.3670\n",
            "Epoch 289/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0755 - val_loss: -2.4157\n",
            "Epoch 290/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0890 - val_loss: -2.3329\n",
            "Epoch 291/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -2.0418 - val_loss: -2.4171\n",
            "Epoch 292/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0848 - val_loss: -2.4021\n",
            "Epoch 293/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.1066 - val_loss: -2.3878\n",
            "Epoch 294/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -2.0507 - val_loss: -2.3291\n",
            "Epoch 295/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -1.9982 - val_loss: -2.3148\n",
            "Epoch 296/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -1.9878 - val_loss: -2.3771\n",
            "Epoch 297/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0007 - val_loss: -2.3038\n",
            "Epoch 298/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: -2.1105 - val_loss: -2.3609\n",
            "Epoch 299/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0676 - val_loss: -2.3343\n",
            "Epoch 300/300\n",
            "31/31 [==============================] - 0s 5ms/step - loss: -2.0415 - val_loss: -2.3437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joQYlW5kwUsH"
      },
      "source": [
        "Plot of the loss for training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "kyt3Ifg7Pdt5",
        "outputId": "7397a676-4f5d-4048-f8c8-7f6f67a10b67"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(history.history['loss'], color='#785ef0')\n",
        "plt.plot(history.history['val_loss'], '--', color='#dc267f')\n",
        "plt.title('Model Reconstruction Loss')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['Training Set', 'Validation Set'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_T5UZWtwZj3"
      },
      "source": [
        "Generating data using the VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGDPT-i6PhIP"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFF7VAeIPkXz"
      },
      "source": [
        "encdd = encoder.predict(x_train)\n",
        "x_hat = decoder.predict(encdd[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWHwrx-dPmZG"
      },
      "source": [
        "def generate_samples(N=10, latend_dim = 2):\n",
        "        noise = np.random.uniform(-2.0, 2.0, (N,latent_dim))\n",
        "        gen = decoder.predict(noise)\n",
        "        return gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JGfljHCPoi7"
      },
      "source": [
        "gen = generate_samples(6000, latent_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cucy68-1gvIr",
        "outputId": "3f383831-549d-4a92-cf2c-c42c7ebe6c16"
      },
      "source": [
        "gen"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.45976895,  0.10558507,  0.05433178, ..., -0.481144  ,\n",
              "        -0.57403725, -0.31245017],\n",
              "       [-0.74723244, -0.22505768,  0.3271051 , ..., -0.25526145,\n",
              "        -0.43545547,  0.03696901],\n",
              "       [-1.7487006 , -0.710349  , -0.30381352, ..., -1.7996763 ,\n",
              "         0.50227535,  1.2723387 ],\n",
              "       ...,\n",
              "       [-0.52585346,  0.5982963 , -0.37925643, ..., -0.6959547 ,\n",
              "        -0.6138645 , -1.5324637 ],\n",
              "       [-0.55518216,  0.4034568 , -0.3676498 , ..., -0.670062  ,\n",
              "        -0.4308877 , -1.0204138 ],\n",
              "       [-1.5142536 , -1.1433444 ,  0.5777633 , ..., -0.2781403 ,\n",
              "         0.47237724,  1.0383723 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykOEakg_whB-"
      },
      "source": [
        "Inverse transform the generated data to compare to original data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPIXgWDoPq1c"
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "new_data = np.around(sc.inverse_transform(gen), decimals=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZHDIjRARRBN"
      },
      "source": [
        "new_df = pd.DataFrame(new_data, columns = ['a', 'e', 'i', 'om', 'q', 'ad', 'per_y', 'data_arc', 'condition_code',\n",
        "       'n_obs_used', 'H', 'neo', 'pha', 'moid', 'class', 'n'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "55WD7vF7mWs6",
        "outputId": "c047d4a9-716e-413c-e268-fa5263330769"
      },
      "source": [
        "new_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>e</th>\n",
              "      <th>i</th>\n",
              "      <th>om</th>\n",
              "      <th>q</th>\n",
              "      <th>ad</th>\n",
              "      <th>per_y</th>\n",
              "      <th>data_arc</th>\n",
              "      <th>condition_code</th>\n",
              "      <th>n_obs_used</th>\n",
              "      <th>H</th>\n",
              "      <th>neo</th>\n",
              "      <th>pha</th>\n",
              "      <th>moid</th>\n",
              "      <th>class</th>\n",
              "      <th>n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.4</td>\n",
              "      <td>0.5</td>\n",
              "      <td>14.700000</td>\n",
              "      <td>152.800003</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2.1</td>\n",
              "      <td>6819.299805</td>\n",
              "      <td>1.2</td>\n",
              "      <td>437.299988</td>\n",
              "      <td>18.900000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.6</td>\n",
              "      <td>8096.500000</td>\n",
              "      <td>1.4</td>\n",
              "      <td>635.099976</td>\n",
              "      <td>18.799999</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>154.300003</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>4270.100098</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-179.899994</td>\n",
              "      <td>20.299999</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>9.600000</td>\n",
              "      <td>162.600006</td>\n",
              "      <td>0.7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.6</td>\n",
              "      <td>3972.800049</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>-116.400002</td>\n",
              "      <td>20.299999</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>10.700000</td>\n",
              "      <td>165.199997</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>4594.299805</td>\n",
              "      <td>0.3</td>\n",
              "      <td>343.000000</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>1.3</td>\n",
              "      <td>0.6</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>162.699997</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>4210.799805</td>\n",
              "      <td>-0.1</td>\n",
              "      <td>342.799988</td>\n",
              "      <td>19.600000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>1.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>10.400000</td>\n",
              "      <td>169.800003</td>\n",
              "      <td>0.7</td>\n",
              "      <td>2.3</td>\n",
              "      <td>1.8</td>\n",
              "      <td>4325.200195</td>\n",
              "      <td>0.2</td>\n",
              "      <td>80.199997</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>1.3</td>\n",
              "      <td>0.6</td>\n",
              "      <td>9.200000</td>\n",
              "      <td>158.899994</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3898.399902</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>348.600006</td>\n",
              "      <td>19.700001</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>1.3</td>\n",
              "      <td>0.6</td>\n",
              "      <td>9.300000</td>\n",
              "      <td>156.500000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3417.600098</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>309.700012</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.3</td>\n",
              "      <td>21.299999</td>\n",
              "      <td>71.699997</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.8</td>\n",
              "      <td>1.1</td>\n",
              "      <td>9959.400391</td>\n",
              "      <td>1.4</td>\n",
              "      <td>571.000000</td>\n",
              "      <td>18.900000</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        a    e          i          om    q  ...  neo  pha  moid  class    n\n",
              "0     1.4  0.5  14.700000  152.800003  0.8  ...  0.9  0.3   0.0    0.8  0.5\n",
              "1     1.2  0.5  18.100000  134.000000  0.8  ...  0.8  0.3   0.0    0.9  0.6\n",
              "2     0.7  0.4  10.200000  154.300003  0.6  ...  0.9  0.7  -0.0    1.3  1.0\n",
              "3     0.8  0.4   9.600000  162.600006  0.7  ...  0.9  0.8  -0.0    1.2  0.9\n",
              "4     1.4  0.6  10.700000  165.199997  0.8  ...  0.6  0.4   0.0    0.8  0.2\n",
              "...   ...  ...        ...         ...  ...  ...  ...  ...   ...    ...  ...\n",
              "5995  1.3  0.6   9.800000  162.699997  0.8  ...  0.5  0.3   0.0    0.8  0.1\n",
              "5996  1.1  0.4  10.400000  169.800003  0.7  ...  0.9  0.8   0.0    1.1  0.8\n",
              "5997  1.3  0.6   9.200000  158.899994  0.8  ...  0.4  0.4   0.0    0.8  0.1\n",
              "5998  1.3  0.6   9.300000  156.500000  0.8  ...  0.6  0.6   0.0    0.9  0.3\n",
              "5999  0.8  0.3  21.299999   71.699997  0.7  ...  0.1  0.6   0.0    1.3  0.9\n",
              "\n",
              "[6000 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf7I67pAwoj3"
      },
      "source": [
        "Create new dataframe with original data + generated data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfy6CZIRwtBX"
      },
      "source": [
        "Overwrite values for 'pha' since they should all be 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI2Xye1SmyoT"
      },
      "source": [
        "for sample in range(0, len(new_df)):\n",
        "    new_df.iloc[sample]['pha'] = 1\n",
        "    new_df.iloc[sample]['neo'] = 1\n",
        "    new_df.iloc[sample]['condition_code'] = round(new_df.iloc[sample]['condition_code'],0)\n",
        "    new_df.iloc[sample]['class'] = round(new_df.iloc[sample]['class'],0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQONT5iNlR5m"
      },
      "source": [
        "new_df = pd.concat([new_df,dataset], axis=0, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NALugD8wxk0"
      },
      "source": [
        "Compare original data to new data.\n",
        "\n",
        "The means look okay, worried about 'data_arc' and 'condition_code' columns since their stats are largely off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "amz67dgjndLp",
        "outputId": "8a5496fe-7b11-4626-b62f-2700c14ca2a0"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>e</th>\n",
              "      <th>i</th>\n",
              "      <th>om</th>\n",
              "      <th>q</th>\n",
              "      <th>ad</th>\n",
              "      <th>per_y</th>\n",
              "      <th>data_arc</th>\n",
              "      <th>condition_code</th>\n",
              "      <th>n_obs_used</th>\n",
              "      <th>H</th>\n",
              "      <th>neo</th>\n",
              "      <th>pha</th>\n",
              "      <th>moid</th>\n",
              "      <th>class</th>\n",
              "      <th>n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.0</td>\n",
              "      <td>976.0</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.000000</td>\n",
              "      <td>976.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.629496</td>\n",
              "      <td>0.502522</td>\n",
              "      <td>13.990116</td>\n",
              "      <td>174.208978</td>\n",
              "      <td>0.755894</td>\n",
              "      <td>2.503098</td>\n",
              "      <td>2.166012</td>\n",
              "      <td>5478.462090</td>\n",
              "      <td>1.728484</td>\n",
              "      <td>366.067623</td>\n",
              "      <td>19.423668</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.022888</td>\n",
              "      <td>1.064549</td>\n",
              "      <td>0.589795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.543703</td>\n",
              "      <td>0.174638</td>\n",
              "      <td>12.635751</td>\n",
              "      <td>101.393970</td>\n",
              "      <td>0.218880</td>\n",
              "      <td>1.030184</td>\n",
              "      <td>1.074204</td>\n",
              "      <td>4820.608061</td>\n",
              "      <td>1.852801</td>\n",
              "      <td>507.229350</td>\n",
              "      <td>1.600561</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014397</td>\n",
              "      <td>0.398630</td>\n",
              "      <td>0.321853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.635232</td>\n",
              "      <td>0.065199</td>\n",
              "      <td>0.146163</td>\n",
              "      <td>0.086611</td>\n",
              "      <td>0.092870</td>\n",
              "      <td>0.959063</td>\n",
              "      <td>0.506299</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.161358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.203076</td>\n",
              "      <td>0.374092</td>\n",
              "      <td>4.837077</td>\n",
              "      <td>85.840703</td>\n",
              "      <td>0.616692</td>\n",
              "      <td>1.628273</td>\n",
              "      <td>1.319618</td>\n",
              "      <td>2366.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>117.000000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010521</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.348871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.544489</td>\n",
              "      <td>0.515976</td>\n",
              "      <td>9.408570</td>\n",
              "      <td>167.546679</td>\n",
              "      <td>0.817470</td>\n",
              "      <td>2.358419</td>\n",
              "      <td>1.919488</td>\n",
              "      <td>4763.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>218.000000</td>\n",
              "      <td>19.600000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.022257</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.513484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.998448</td>\n",
              "      <td>0.624271</td>\n",
              "      <td>19.804329</td>\n",
              "      <td>261.195511</td>\n",
              "      <td>0.934633</td>\n",
              "      <td>3.185851</td>\n",
              "      <td>2.825190</td>\n",
              "      <td>6904.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>416.250000</td>\n",
              "      <td>20.700000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.034418</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.746909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.341513</td>\n",
              "      <td>0.955961</td>\n",
              "      <td>75.377946</td>\n",
              "      <td>359.849201</td>\n",
              "      <td>1.054989</td>\n",
              "      <td>6.120684</td>\n",
              "      <td>6.108337</td>\n",
              "      <td>32277.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>6102.000000</td>\n",
              "      <td>22.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.049977</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.946729</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                a           e           i  ...        moid       class           n\n",
              "count  976.000000  976.000000  976.000000  ...  976.000000  976.000000  976.000000\n",
              "mean     1.629496    0.502522   13.990116  ...    0.022888    1.064549    0.589795\n",
              "std      0.543703    0.174638   12.635751  ...    0.014397    0.398630    0.321853\n",
              "min      0.635232    0.065199    0.146163  ...    0.000047    0.000000    0.161358\n",
              "25%      1.203076    0.374092    4.837077  ...    0.010521    1.000000    0.348871\n",
              "50%      1.544489    0.515976    9.408570  ...    0.022257    1.000000    0.513484\n",
              "75%      1.998448    0.624271   19.804329  ...    0.034418    1.000000    0.746909\n",
              "max      3.341513    0.955961   75.377946  ...    0.049977    3.000000    1.946729\n",
              "\n",
              "[8 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "76rwc1OBm4Qf",
        "outputId": "3ce87ea8-4147-44cd-ea98-12ebd16d215a"
      },
      "source": [
        "new_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>e</th>\n",
              "      <th>i</th>\n",
              "      <th>om</th>\n",
              "      <th>q</th>\n",
              "      <th>ad</th>\n",
              "      <th>per_y</th>\n",
              "      <th>data_arc</th>\n",
              "      <th>n_obs_used</th>\n",
              "      <th>H</th>\n",
              "      <th>moid</th>\n",
              "      <th>n</th>\n",
              "      <th>w</th>\n",
              "      <th>albedo</th>\n",
              "      <th>rot_per</th>\n",
              "      <th>GM</th>\n",
              "      <th>BV</th>\n",
              "      <th>UB</th>\n",
              "      <th>IR</th>\n",
              "      <th>G</th>\n",
              "      <th>per</th>\n",
              "      <th>ma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>845712.000000</td>\n",
              "      <td>845714.000000</td>\n",
              "      <td>845714.000000</td>\n",
              "      <td>845714.000000</td>\n",
              "      <td>845714.000000</td>\n",
              "      <td>845708.000000</td>\n",
              "      <td>845713.000000</td>\n",
              "      <td>830240.000000</td>\n",
              "      <td>845714.000000</td>\n",
              "      <td>843025.000000</td>\n",
              "      <td>829272.000000</td>\n",
              "      <td>8.457120e+05</td>\n",
              "      <td>839714.000000</td>\n",
              "      <td>136409.000000</td>\n",
              "      <td>18796.000000</td>\n",
              "      <td>1.400000e+01</td>\n",
              "      <td>1021.000000</td>\n",
              "      <td>979.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>8.397080e+05</td>\n",
              "      <td>839706.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.745729</td>\n",
              "      <td>0.157929</td>\n",
              "      <td>8.987643</td>\n",
              "      <td>168.312144</td>\n",
              "      <td>2.393071</td>\n",
              "      <td>3.376982</td>\n",
              "      <td>6.825528</td>\n",
              "      <td>5693.195284</td>\n",
              "      <td>259.952614</td>\n",
              "      <td>16.804608</td>\n",
              "      <td>1.413073</td>\n",
              "      <td>2.398637e-01</td>\n",
              "      <td>181.075796</td>\n",
              "      <td>0.130067</td>\n",
              "      <td>21.136772</td>\n",
              "      <td>7.821928e+00</td>\n",
              "      <td>0.769212</td>\n",
              "      <td>0.364396</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.178739</td>\n",
              "      <td>2.505533e+03</td>\n",
              "      <td>180.659892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>113.978566</td>\n",
              "      <td>0.097688</td>\n",
              "      <td>6.670059</td>\n",
              "      <td>102.787248</td>\n",
              "      <td>2.229512</td>\n",
              "      <td>12.703860</td>\n",
              "      <td>251.368129</td>\n",
              "      <td>4199.314621</td>\n",
              "      <td>371.294394</td>\n",
              "      <td>1.828873</td>\n",
              "      <td>2.245537</td>\n",
              "      <td>8.830242e-02</td>\n",
              "      <td>104.023854</td>\n",
              "      <td>0.109994</td>\n",
              "      <td>73.131751</td>\n",
              "      <td>1.678880e+01</td>\n",
              "      <td>0.088625</td>\n",
              "      <td>0.095780</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.134603</td>\n",
              "      <td>9.213979e+04</td>\n",
              "      <td>106.562235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-104279.220927</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007546</td>\n",
              "      <td>0.000388</td>\n",
              "      <td>0.070511</td>\n",
              "      <td>0.773684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-362.200012</td>\n",
              "      <td>-1.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.926897e-08</td>\n",
              "      <td>0.001666</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.004389</td>\n",
              "      <td>2.100000e-09</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>1.511339e+02</td>\n",
              "      <td>-67.136826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.381131</td>\n",
              "      <td>0.091830</td>\n",
              "      <td>4.091712</td>\n",
              "      <td>80.662370</td>\n",
              "      <td>1.966778</td>\n",
              "      <td>2.769281</td>\n",
              "      <td>3.674371</td>\n",
              "      <td>3616.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>15.900000</td>\n",
              "      <td>0.973190</td>\n",
              "      <td>1.902693e-01</td>\n",
              "      <td>91.041603</td>\n",
              "      <td>0.053000</td>\n",
              "      <td>4.210000</td>\n",
              "      <td>1.022225e-03</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.289000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.345555e+03</td>\n",
              "      <td>86.642618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.641934</td>\n",
              "      <td>0.144384</td>\n",
              "      <td>7.314697</td>\n",
              "      <td>160.036370</td>\n",
              "      <td>2.221255</td>\n",
              "      <td>3.033352</td>\n",
              "      <td>4.294287</td>\n",
              "      <td>5806.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>16.800000</td>\n",
              "      <td>1.233325</td>\n",
              "      <td>2.294469e-01</td>\n",
              "      <td>181.669478</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>6.653000</td>\n",
              "      <td>6.192500e-01</td>\n",
              "      <td>0.743000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.190000</td>\n",
              "      <td>1.570524e+03</td>\n",
              "      <td>181.517775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.993456</td>\n",
              "      <td>0.200775</td>\n",
              "      <td>12.303664</td>\n",
              "      <td>251.325529</td>\n",
              "      <td>2.575732</td>\n",
              "      <td>3.355380</td>\n",
              "      <td>5.179253</td>\n",
              "      <td>7280.000000</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>17.600000</td>\n",
              "      <td>1.588030</td>\n",
              "      <td>2.681270e-01</td>\n",
              "      <td>271.521717</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>12.624250</td>\n",
              "      <td>6.500000e+00</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.439000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.894184e+03</td>\n",
              "      <td>274.301731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3043.149073</td>\n",
              "      <td>1.201134</td>\n",
              "      <td>175.188725</td>\n",
              "      <td>359.999800</td>\n",
              "      <td>80.424175</td>\n",
              "      <td>6081.841956</td>\n",
              "      <td>167877.712688</td>\n",
              "      <td>72684.000000</td>\n",
              "      <td>9325.000000</td>\n",
              "      <td>33.200000</td>\n",
              "      <td>79.501300</td>\n",
              "      <td>2.381994e+00</td>\n",
              "      <td>359.999833</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3240.000000</td>\n",
              "      <td>6.262840e+01</td>\n",
              "      <td>1.077000</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>6.131733e+07</td>\n",
              "      <td>491.618014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   a              e  ...           per             ma\n",
              "count  845712.000000  845714.000000  ...  8.397080e+05  839706.000000\n",
              "mean        2.745729       0.157929  ...  2.505533e+03     180.659892\n",
              "std       113.978566       0.097688  ...  9.213979e+04     106.562235\n",
              "min   -104279.220927       0.000000  ...  1.511339e+02     -67.136826\n",
              "25%         2.381131       0.091830  ...  1.345555e+03      86.642618\n",
              "50%         2.641934       0.144384  ...  1.570524e+03     181.517775\n",
              "75%         2.993456       0.200775  ...  1.894184e+03     274.301731\n",
              "max      3043.149073       1.201134  ...  6.131733e+07     491.618014\n",
              "\n",
              "[8 rows x 22 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVojWVOkn8ej"
      },
      "source": [
        "original data\n",
        "\n",
        "| | a |\te |\ti |\tom |\tq |\tad |\tper_y |\tdata_arc |\tcondition_code |\tn_obs_used |\tH |\tneo |\tpha |\tmoid |\tclass |\tn |\n",
        "|------ | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- |\n",
        "| count\t| 1076.000000\t| 1076.000000\t| 1076.000000\t| 1076.000000\t| 1076.000000\t| 1076.000000\t| 1076.000000\t| 1076.000000\t| 1076.000000\t| 1076.000000\t| 1076.000000\t| 1076.0\t| 1076.0\t| 1076.000000\t| 1076.00000\t| 1076.000000 |\n",
        "| mean\t| 1.570993\t| 0.548756\t| 12.782856\t| 158.111490\t| 0.778580\t| 2.363405\t| 2.057646\t| 4969.404275\t| 1.660781\t| 332.139405\t| 17.711431\t| 1.0\t| 1.0\t| 0.113698\t| 1.05855\t| 0.627919 |\n",
        "| std\t| 0.549136\t| 0.220326\t| 12.611428\t| 108.884538\t| 0.220181\t| 1.073868\t| 1.077633\t| 4858.818895\t| 1.777164\t| 494.564315\t| 5.564534\t| 0.0\t| 0.0\t| 0.284161\t| 0.38010\t| 0.328864 |\n",
        "\n",
        "\n",
        "new_data\n",
        "\n",
        "\n",
        "| | a |\te |\ti |\tom |\tq |\tad |\tper_y |\tdata_arc |\tcondition_code |\tn_obs_used |\tH |\tneo |\tpha |\tmoid |\tclass |\tn |\n",
        "|------ | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- |\n",
        "| count | 1176.000000 |\t1176.000000 |\t1176.000000 |\t1176.000000 |\t1176.000000 |\t1176.000000 |\t1176.000000 |\t1176.000000 |\t1176.000000 |\t1176.000000 |\t1176.000000 |\t1176.000000 |\t1176.0 |\t1176.000000 |\t1176.000000 |\t1176.000000 |\n",
        "|mean\t| 1.582558\t| 0.546056\t| 12.647834\t| 158.912383\t| 0.780061\t| 2.408864\t| 2.099683\t| 4967.245833\t| 1.710884\t| 317.770578\t| 17.814711\t| 0.959099\t| 1.0\t| 0.104030\t| 1.050255\t| 0.611344 |\n",
        "| std\t| 0.530422\t| 0.211897\t| 12.082260\t| 104.666288\t| 0.211784\t| 1.043321\t| 1.046778\t| 4670.214634\t| 1.725346\t| 476.338905\t| 5.334264\t| 0.150355\t| 0.0\t0.273646\t| 0.365769\t| 0.322200 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqmpN4Aew8NY"
      },
      "source": [
        "Store whole dataset as csv to be used in classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgwKqVJhnFIq"
      },
      "source": [
        "new_df.to_csv('/content/drive/MyDrive/ML/Project/Asteroid_VAE_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}